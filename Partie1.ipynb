{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d72bfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...    News   \n",
      "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
      "2  On Friday, it was revealed that former Milwauk...    News   \n",
      "3  On Christmas day, Donald Trump announced that ...    News   \n",
      "4  Pope Francis used his annual Christmas Day mes...    News   \n",
      "\n",
      "                date  Label  \n",
      "0  December 31, 2017      0  \n",
      "1  December 31, 2017      0  \n",
      "2  December 30, 2017      0  \n",
      "3  December 29, 2017      0  \n",
      "4  December 25, 2017      0  \n",
      "Index(['title', 'text', 'subject', 'date', 'Label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv(\"fake.csv\")\n",
    "\n",
    "# Ajout de la colonne \"Label\" (0 = news vérifiée, 1 = fake news)\n",
    "# Si le dataset contient déjà une indication (ex: 'fake'/'real'), on le convertit\n",
    "data[\"Label\"] = data[\"subject\"].apply(lambda x: 1 if x == \"fake\" else 0)\n",
    "\n",
    "# Vérification du format des données\n",
    "print(data.head())\n",
    "print(data.columns)  # Vérification des colonnes après modification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2edec790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avant suppression des doublons : 23481\n"
     ]
    }
   ],
   "source": [
    "# Affichage du nombre de lignes avant nettoyage\n",
    "print(f\"Nombre de lignes avant suppression des doublons : {data.shape[0]}\")\n",
    "\n",
    "# Suppression des doublons\n",
    "data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5091f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes après suppression des doublons : 23478\n",
      "Nombre de lignes après suppression des valeurs manquantes : 23478\n"
     ]
    }
   ],
   "source": [
    "# Vérification après suppression des doublons\n",
    "print(f\"Nombre de lignes après suppression des doublons : {data.shape[0]}\")\n",
    "\n",
    "# Suppression des valeurs manquantes dans la colonne \"text\"\n",
    "data = data.dropna(subset=['text'])\n",
    "\n",
    "# Vérification après suppression des valeurs manquantes\n",
    "print(f\"Nombre de lignes après suppression des valeurs manquantes : {data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06126149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...   \n",
      "1  House Intelligence Committee Chairman Devin Nu...   \n",
      "2  On Friday, it was revealed that former Milwauk...   \n",
      "3  On Christmas day, Donald Trump announced that ...   \n",
      "4  Pope Francis used his annual Christmas Day mes...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  donald trump just couldn t wish all americans ...  \n",
      "1  house intelligence committee chairman devin nu...  \n",
      "2  on friday it was revealed that former milwauke...  \n",
      "3  on christmas day donald trump announced that h...  \n",
      "4  pope francis used his annual christmas day mes...  \n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des textes : conversion en minuscules et suppression de la ponctuation\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convertir en minuscules\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Supprimer la ponctuation\n",
    "    return text\n",
    "\n",
    "# Application du nettoyage\n",
    "data[\"clean_text\"] = data[\"text\"].apply(clean_text)\n",
    "\n",
    "# Vérification après nettoyage\n",
    "print(data[[\"text\", \"clean_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3937d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données terminée avec succès !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vectorisation avec TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(data[\"clean_text\"])\n",
    "y = data[\"Label\"]  # Vérifie que \"Label\" existe bien dans le fichier CSV\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Préparation des données terminée avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cfcb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle Random Forest : 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(f\"Précision du modèle Random Forest : {accuracy_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "import joblib\n",
    "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec080bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BOKA ESTHER\\OneDrive - Groupe INSEEC (POCE)\\Bureau\\ECOLE\\S2\\Projets\\Intégration_IA\\Données du projet\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.9919 - loss: 0.0424 - val_accuracy: 1.0000 - val_loss: 1.2425e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 8.9789e-06 - val_accuracy: 1.0000 - val_loss: 2.4031e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3349e-06 - val_accuracy: 1.0000 - val_loss: 8.9729e-07\n",
      "Epoch 4/5\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.8915e-07 - val_accuracy: 1.0000 - val_loss: 4.3002e-07\n",
      "Epoch 5/5\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.7335e-07 - val_accuracy: 1.0000 - val_loss: 2.3423e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#Reseau de neurones\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Définition du modèle neuronal\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Sortie binaire\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement\n",
    "model.fit(X_train.toarray(), y_train, epochs=5, batch_size=32, validation_data=(X_test.toarray(), y_test))\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save(\"fake_news_nn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f1b9559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation Random Forest :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4696\n",
      "\n",
      "    accuracy                           1.00      4696\n",
      "   macro avg       1.00      1.00      1.00      4696\n",
      "weighted avg       1.00      1.00      1.00      4696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Évaluation Random Forest :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Données du projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
